#!/usr/bin/python3

import string
from itertools import product
import random
import argparse
import json
import os

SKELETON="""
#!/bin/bash

# This was auto-generated by autoscript.
# Description: {description}

# Prelude commands
{prelude}

# Env vars
{env_vars}

{cmd} \\
{flags}

"""

def enumerate_dict(inp):
    # # https://stackoverflow.com/questions/5228158/cartesian-product-of-a-dictionary-of-lists
    return (dict(zip(inp.keys(), values)) for values in product(*inp.values()))

def parse_args():
    parser = argparse.ArgumentParser("")
    parser.add_argument("--jobs_per_chunk", type=int, default=1,
                        help="""If this is > 1, then group
                        experiments by that many chunks. For instance,
                        if we had 10 HP configs and `--chunk=2`, then
                        five of those would go into e.g. `exps/<name>/c1`
                        and the other five into `exps/<name>/c2`. The
                        purpose of this feature is to facilitate
                        economical use of GPUs by easily running each
                        chunk on just one GPU, if required.
                        """)
    parser.add_argument('--out_dir', type=str, default="exps")
    parser.add_argument('--json', required=True)
    parser.add_argument('--dry_run', action='store_true',
                        help="""If true, do not produce any
                        files -- just simulate the output/
                        """)

    args = parser.parse_args()
    return args

def infer_type(s):
    # Figure out if we need to wrap the string s
    # in quotes or not.
    try:
        float(s)
        return s
    except:
        return '"' + s + '"'

args = parse_args()

print(args)

#cmd = "\n".join(cmd)
#flags = " \\ \n".join([(str(a) + " " + str(b)) for a,b in zip(elem.keys(), elem.values())])

dd = json.loads(open(args.json).read())

experiment_name = dd['metadata']['name']
experiment_name += ("-" + "".join([ random.choice(string.ascii_letters[0:26]) for j in range(5) ]))
print(experiment_name)

desc = dd['metadata']['description']

cmd = dd['cmd']
prelude = dd['prelude']

cfgs = [elem for elem in enumerate_dict(dd['parameters'])]
print("How many HP cfgs generated: %i" % len(cfgs))

idx2chunk = []
if args.jobs_per_chunk > 0:
    for idx, k in enumerate(range(0, len(cfgs), args.jobs_per_chunk)):
        #print(k, k+args.jobs_per_chunk, idx)
        # Map [k, k+args.jobs_per_chunk] to idx
        for z in range(k, k+args.jobs_per_chunk):
            idx2chunk.append(idx)
elif args.jobs_per_chunk == 0:
    idx2chunk += [0]*len(cfgs)
else:
    raise Exception("args.jobs_per_chunk must be >= 0")
print("idx2chunk:", idx2chunk)

ENV_VAR_TEMPLATE = "export {}={}"
env_vars = ENV_VAR_TEMPLATE.format("EXPERIMENT_NAME", experiment_name)

for idx, elem in enumerate(cfgs):
    this_id = "{:04d}".format(idx)
    if args.jobs_per_chunk == 1:
        filename = "%s.sh" % this_id
    else:
        filename = "%s_chunk%i.sh" % (this_id, idx2chunk[idx])
    out_file = "%s/%s/%s" % (args.out_dir, experiment_name, filename)
    flags = " \\\n".join([(str(a) + "=" + infer_type(str(b)) ) for a,b in \
                           zip(elem.keys(), elem.values())])
    print("out file :", out_file)
    if not args.dry_run:
        if not os.path.exists(os.path.dirname(out_file)):
            os.makedirs(os.path.dirname(out_file))
        with open(out_file, "w") as f:
            f.write(SKELETON.format(prelude=prelude,
                                    env_vars=env_vars,
                                    description=desc,
                                    cmd=cmd,
                                    flags=flags) + "\n")
